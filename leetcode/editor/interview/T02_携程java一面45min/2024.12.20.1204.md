# 实习介绍（根本不深入问）

# 项目介绍（疯狂打断，询问库表结构，以及设置一堆场景题）

# 如果你的评论有一百万条，你现在存储在数据库，要怎么做查询

在处理一百万条评论数据并高效执行查询时，以下是一些优化方法和数据库设计方案：

---

## 1. **选择合适的数据库**
- 如果数据量大且查询性能要求高，选择合适的数据库是关键：
    - **关系型数据库（RDBMS）：** 例如 MySQL、PostgreSQL，适合复杂查询和事务处理。
    - **NoSQL 数据库：** 例如 MongoDB（文档型），适合灵活的非结构化数据。
    - **搜索引擎数据库：** 例如 Elasticsearch，擅长全文搜索和复杂筛选。

---

## 2. **数据库表设计**
设计表结构以满足查询需求：
```sql
CREATE TABLE comments (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    user_id BIGINT NOT NULL,  -- 用户ID
    post_id BIGINT NOT NULL,  -- 关联的帖子ID
    content TEXT NOT NULL,    -- 评论内容
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, -- 创建时间
    INDEX(post_id),           -- 针对帖子查询的索引
    FULLTEXT(content)         -- 针对全文搜索的索引（MySQL支持）
);
```

---

## 3. **查询优化策略**
### **(1) 索引**
创建合适的索引以加速查询：
- **B树索引：** 用于范围查询和排序（如 `post_id` 或 `created_at`）。
- **全文索引：** 用于关键词搜索（如 `content` 字段）。

### **(2) 分页查询**
避免一次性加载大量数据，通过分页查询实现高效加载：
```sql
SELECT * FROM comments 
WHERE post_id = 123 
ORDER BY created_at DESC 
LIMIT 20 OFFSET 40; -- 分页查询
```

### **(3) 分片**
- 按照 `post_id` 或 `user_id` 对数据进行逻辑分片，分散查询压力。

### **(4) 缓存**
- 使用 Redis 等缓存系统存储高频访问的数据，减少数据库压力。

---

## 4. **全文搜索优化**
如果需要处理评论的关键词搜索，Elasticsearch 是一个很好的选择：
### **Elasticsearch 查询示例**
```json
{
  "query": {
    "match": {
      "content": "关键字"
    }
  }
}
```

---

## 5. **数据分区或分库分表**
对于大规模数据，可对数据进行分区或分库分表：
- **分区表：** 按照日期或 `post_id` 分区。
- **分库分表：** 按 `user_id` 或 `post_id` 分布到不同的库。

---

## 6. **示例查询场景**
### (1) 查询特定帖子的最新评论
```sql
SELECT * FROM comments 
WHERE post_id = 123 
ORDER BY created_at DESC 
LIMIT 10;
```

### (2) 按关键词搜索评论
使用全文索引：
```sql
SELECT * FROM comments 
WHERE MATCH(content) AGAINST ('关键字');
```

---

通过合理的表设计、索引优化、缓存策略和分布式架构，百万级数据的查询效率可以显著提升。如果有更复杂需求，可以进一步探索如实时流处理或批量分析的方法。

# 你的点赞量要持久化到数据库，那你这个定时任务设置的不好导致redis内存满了丢弃了一些数据怎么办

如果 Redis 内存满了导致点赞数据丢失，这是一个常见的分布式缓存持久化问题，通常可以采取以下策略来避免或减轻数据丢失的影响：

---

## 1. **问题分析**
Redis 内存满了丢弃数据的主要原因：
- **内存限制：** Redis 设置了最大内存 (`maxmemory`)，超出时会根据配置的淘汰策略（如 LRU、LFU 等）丢弃数据。
- **持久化未及时：** 如果 Redis 没有开启或未及时完成数据持久化，数据可能会在系统崩溃或内存淘汰时丢失。
- **定时任务设计不合理：** 数据从 Redis 同步到数据库的任务频率过低，导致来不及同步。

---

## 2. **改进策略**
### **(1) 提高 Redis 的可靠性**
- **增加 Redis 的内存：**
    - 检查是否有其他不必要的数据占用了 Redis 的内存。
    - 增加 Redis 服务器的内存容量。

- **优化 Redis 淘汰策略：**
    - 设置 `maxmemory-policy` 为 `volatile-lru` 或 `volatile-ttl`，确保仅淘汰过期数据。

- **启用持久化机制：**
    - **RDB 快照：** 定期保存 Redis 的全量数据。
      ```bash
      save 900 1
      save 300 10
      ```
    - **AOF（Append Only File）：** 持久化每次写入操作。
      ```bash
      appendonly yes
      ```

---

### **(2) 改进定时任务设计**
- **高频写入：**
    - 缩短定时任务的执行周期，例如每分钟将 Redis 的数据增量写入数据库。
- **按增量更新：**
    - 仅将 Redis 中变化的数据（如点赞量增量）写入数据库，减少写入量。
    - 例如，使用 Redis 的 `HINCRBY` 记录增量：
      ```bash
      HINCRBY post_likes:post_id 1
      ```

---

### **(3) 使用消息队列**
引入消息队列（如 Kafka 或 RabbitMQ），用于收集用户点赞操作：
- 用户点赞时，将操作写入消息队列。
- 后端消费者从队列读取操作并更新数据库，避免完全依赖 Redis。

---

### **(4) 数据冗余设计**
- **双写机制：**
    - 在用户点赞时，同时更新 Redis 和数据库，确保数据库中始终有一份最新的数据。
    - 例如：
      ```java
      public void likePost(int postId) {
          redis.incr("post_likes:" + postId);
          database.updateLikes(postId);
      }
      ```

- **备用存储：**
    - 将点赞数据存储到备份存储系统（如文件系统或分布式存储）。

---

### **(5) 数据恢复机制**
在 Redis 数据丢失后，自动从数据库恢复：
- 在 Redis 启动时，通过数据库全量数据重建 Redis 缓存：
  ```java
  Map<Integer, Integer> likes = database.getAllLikes();
  for (Map.Entry<Integer, Integer> entry : likes.entrySet()) {
      redis.set("post_likes:" + entry.getKey(), entry.getValue());
  }
  ```

---

## 3. **解决方案示例**
假设我们有以下需求：
- 用户点赞，Redis 保存数据。
- 每分钟将 Redis 中的点赞增量同步到数据库。

### Redis 结构
```bash
HSET post_likes:post_id user_id 1  # 记录用户点赞
```

### 定时任务伪代码
```java
public void syncLikesToDatabase() {
    // 获取 Redis 中所有点赞数据
    Map<Integer, Map<Integer, Integer>> likesData = redis.hgetAll("post_likes:*");
    for (Map.Entry<Integer, Map<Integer, Integer>> entry : likesData.entrySet()) {
        int postId = entry.getKey();
        int likeCount = entry.getValue().size();
        
        // 同步增量数据到数据库
        database.updateLikes(postId, likeCount);
        
        // 清除 Redis 中已同步的数据
        redis.del("post_likes:" + postId);
    }
}
```

---

通过上述措施，可以显著减少因 Redis 内存满而导致的数据丢失问题。**推荐的最终方案是结合消息队列和双写机制，实现更可靠的系统设计。**

# 如果很多条评论，你怎么做能够快速找出点赞量top100


如果需要从大量的评论中快速找出点赞量（或其他类似的排序指标）排名前100的评论，可以通过以下几种方式来实现，依据数据量和技术栈的不同，选用合适的技术和算法。

### 1. **使用排序算法**
最简单的一种方式是将所有评论按照点赞量进行排序，然后选出点赞量排名前100的评论。

#### 方法：
- **排序算法**：可以使用快速排序（QuickSort）或归并排序（MergeSort）等O(n log n)时间复杂度的排序算法。
- **提取前100条评论**：在排序完成后，直接取前100条评论。

#### 示例：
```java
import java.util.*;

class Comment {
    String text;
    int likes;

    Comment(String text, int likes) {
        this.text = text;
        this.likes = likes;
    }
}

public class Main {
    public static void main(String[] args) {
        // 示例数据
        List<Comment> comments = new ArrayList<>();
        comments.add(new Comment("评论1", 50));
        comments.add(new Comment("评论2", 100));
        comments.add(new Comment("评论3", 75));
        comments.add(new Comment("评论4", 120));

        // 排序，按点赞量从高到低排序
        comments.sort((c1, c2) -> Integer.compare(c2.likes, c1.likes));

        // 取前100条评论
        List<Comment> top100Comments = comments.subList(0, Math.min(100, comments.size()));

        // 输出前100条评论
        for (Comment comment : top100Comments) {
            System.out.println(comment.text + ": " + comment.likes + "点赞");
        }
    }
}
```

### 2. **使用堆（Heap）**
当评论的数量非常大时（例如百万级别以上），一次性排序可能会消耗大量内存并且效率较低。此时，可以使用**最小堆**来优化问题，只维护当前的前100条评论。

#### 方法：
- 使用**最小堆**（优先队列）来维护前100个点赞量最多的评论。
- 每次遍历一个评论时，如果评论的点赞量大于堆中的最小值，就将堆顶的最小值替换为当前评论。
- 最小堆的时间复杂度是O(log k)，其中k是堆的大小（即100）。所以遍历n条评论的时间复杂度是O(n log k)。

#### 示例：
```java
import java.util.*;

class Comment {
    String text;
    int likes;

    Comment(String text, int likes) {
        this.text = text;
        this.likes = likes;
    }
}

public class Main {
    public static void main(String[] args) {
        // 示例数据
        List<Comment> comments = new ArrayList<>();
        comments.add(new Comment("评论1", 50));
        comments.add(new Comment("评论2", 100));
        comments.add(new Comment("评论3", 75));
        comments.add(new Comment("评论4", 120));
        comments.add(new Comment("评论5", 200));

        // 使用最小堆来维护前100条点赞最多的评论
        PriorityQueue<Comment> minHeap = new PriorityQueue<>(Comparator.comparingInt(c -> c.likes));

        // 遍历所有评论
        for (Comment comment : comments) {
            // 如果堆的大小小于100，就加入堆
            if (minHeap.size() < 100) {
                minHeap.offer(comment);
            } else {
                // 如果堆满了，且当前评论的点赞量大于堆顶的最小值，则替换堆顶
                if (comment.likes > minHeap.peek().likes) {
                    minHeap.poll();  // 移除堆顶最小的评论
                    minHeap.offer(comment);  // 插入当前评论
                }
            }
        }

        // 输出前100条评论
        List<Comment> top100Comments = new ArrayList<>(minHeap);
        top100Comments.sort((c1, c2) -> Integer.compare(c2.likes, c1.likes));  // 排序以便输出按点赞量排序

        for (Comment comment : top100Comments) {
            System.out.println(comment.text + ": " + comment.likes + "点赞");
        }
    }
}
```

### 3. **分布式处理（大数据量）**
如果评论数据非常庞大，甚至达到了亿级别，单机排序或者堆的操作可能无法满足性能需求。此时可以使用分布式计算框架来处理，如：

- **Hadoop**：可以将评论数据分割成多个块，分别排序并最终汇总。
- **Apache Spark**：使用Spark的`top`函数或`reduceByKey`操作来高效地找出前100个点赞量最多的评论。

Spark示例代码：
```scala
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession

case class Comment(text: String, likes: Int)

object Main {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("Top 100 Comments").getOrCreate()

    // 假设数据已经加载为RDD
    val comments: RDD[Comment] = spark.sparkContext.parallelize(Seq(
      Comment("评论1", 50),
      Comment("评论2", 100),
      Comment("评论3", 75),
      Comment("评论4", 120),
      Comment("评论5", 200)
    ))

    // 按照点赞量排序并取前100条
    val top100Comments = comments.sortBy(-_.likes).take(100)

    // 输出结果
    top100Comments.foreach(comment => println(s"${comment.text}: ${comment.likes}点赞"))

    spark.stop()
  }
}
```

### 4. **SQL查询优化**
如果评论数据存储在关系型数据库中，可以使用SQL查询来高效地查询点赞量最多的前100条评论。一般而言，数据库会对排序和分页有优化，适合处理海量数据。

```sql
SELECT * FROM comments
ORDER BY likes DESC
LIMIT 100;
```

### 总结
- **小规模数据**：可以直接使用排序（如快速排序）来处理。
- **大规模数据**：使用最小堆（优先队列）来维持前100条评论，保证时间复杂度较低。
- **超大规模数据**：使用分布式框架如Hadoop或Spark来处理数据。
- **数据库中查询**：可以通过SQL查询直接从数据库中检索前100条评论。

根据具体场景的不同，可以选择合适的算法和技术方案来高效处理大量评论数据。

# sql，找出总分最高的学生id，以及如果科目有重复数据，你直接sum会有问题，怎么解决

在SQL中，如果要找出总分最高的学生ID，并且考虑到科目有重复数据的情况（可能是因为同一科目可能在不同记录中重复），直接使用`SUM`函数可能会出现错误的总分。为了正确地计算总分，首先需要对科目进行去重，然后再计算总分。

### 1. **解决重复科目问题**
要避免重复科目对总分的影响，我们可以通过对科目进行去重来确保每个学生在每个科目的分数只计入一次。可以通过以下方式来实现：
- 使用`DISTINCT`关键字对科目进行去重。
- 通过子查询或使用`GROUP BY`和`SUM`结合去重的方式来正确计算总分。

### 2. **SQL 查询示例**

假设有一个学生成绩表`student_scores`，表结构如下：

| student_id | subject  | score |
|------------|----------|-------|
| 1          | Math     | 90    |
| 1          | Math     | 85    |
| 1          | English  | 88    |
| 2          | Math     | 78    |
| 2          | English  | 92    |
| 2          | English  | 80    |

#### 2.1 通过子查询去重并计算总分
我们可以使用一个子查询来去重每个学生的科目，确保每个科目只计一次，然后在外层查询中计算总分。

```sql
SELECT student_id, SUM(score) AS total_score
FROM (
    SELECT DISTINCT student_id, subject, score
    FROM student_scores
) AS distinct_scores
GROUP BY student_id
ORDER BY total_score DESC
LIMIT 1;
```

**解释**：
- 内部查询 `SELECT DISTINCT student_id, subject, score` 会去掉重复的科目记录。这样每个科目的分数只会被计入一次。
- 外部查询对去重后的数据进行分组，并计算每个学生的总分。
- `ORDER BY total_score DESC` 按总分降序排列，`LIMIT 1` 只返回总分最高的学生。

#### 2.2 使用 `GROUP BY` 和 `MAX` 去重
另一种方法是通过`GROUP BY`来去重科目，只按每个科目的最高分来计算总分。这种方法适用于你希望对每个科目取最高分，而不是去除重复记录。

```sql
SELECT student_id, SUM(MAX(score)) AS total_score
FROM student_scores
GROUP BY student_id, subject
ORDER BY total_score DESC
LIMIT 1;
```

**解释**：
- `GROUP BY student_id, subject` 确保每个学生每个科目的分数只计算一次。
- `MAX(score)` 用来选取每个科目中的最高分，避免同一科目重复计入总分。
- `SUM(MAX(score))` 计算每个学生的总分。

### 3. **总结**
- 如果表中存在重复的科目数据，可以通过**去重**的方式来确保每个科目只被计入一次。
- 可以使用`DISTINCT`关键字或者在`GROUP BY`中使用`MAX()`函数来避免重复科目影响总分。
- 最终通过`SUM()`函数计算每个学生的总分，并排序取出总分最高的学生ID。

上述方法能够帮助你准确计算每个学生的总分，并且避免重复科目对总分计算的影响。

# 反问